import pandas as pd
import os
import json
import httpx
import re
from typing import AsyncGenerator, List, Dict, Any, Optional
from dotenv import load_dotenv
from utils.logger import get_logger
from utils.api_utils import APIUtils
from datetime import datetime

# è·å–æ—¥å¿—å™¨
logger = get_logger()

class AIAnalyzer:
    """
    å¼‚æ­¥AIåˆ†ææœåŠ¡
    è´Ÿè´£è°ƒç”¨AI APIå¯¹è‚¡ç¥¨æ•°æ®è¿›è¡Œåˆ†æ
    """
    
    def __init__(self, custom_api_url=None, custom_api_key=None, custom_api_model=None, custom_api_timeout=None):
        """
        åˆå§‹åŒ–AIåˆ†ææœåŠ¡
        
        Args:
            custom_api_url: è‡ªå®šä¹‰API URL
            custom_api_key: è‡ªå®šä¹‰APIå¯†é’¥
            custom_api_model: è‡ªå®šä¹‰APIæ¨¡å‹
            custom_api_timeout: è‡ªå®šä¹‰APIè¶…æ—¶æ—¶é—´
        """
        # åŠ è½½ç¯å¢ƒå˜é‡
        load_dotenv()
        
        # è®¾ç½®APIé…ç½®ï¼Œå¤„ç†ç©ºå­—ç¬¦ä¸²ç¯å¢ƒå˜é‡
        self.API_URL = (custom_api_url if custom_api_url and custom_api_url.strip() else None) or \
                      (os.getenv('API_URL') if os.getenv('API_URL') and os.getenv('API_URL').strip() else None) or \
                      'https://api.openai.com/v1/chat/completions'
        
        self.API_KEY = (custom_api_key if custom_api_key and custom_api_key.strip() else None) or \
                      (os.getenv('API_KEY') if os.getenv('API_KEY') and os.getenv('API_KEY').strip() else '') or \
                      ''
        
        self.API_MODEL = (custom_api_model if custom_api_model and custom_api_model.strip() else None) or \
                        (os.getenv('API_MODEL') if os.getenv('API_MODEL') and os.getenv('API_MODEL').strip() else None) or \
                        'gpt-4o'
        
        # å¤„ç†APIè¶…æ—¶å‚æ•°ï¼Œç¡®ä¿ç©ºå­—ç¬¦ä¸²ä¹Ÿèƒ½æ­£ç¡®å¤„ç†
        timeout_str = None
        if custom_api_timeout and custom_api_timeout.strip():
            timeout_str = custom_api_timeout.strip()
        elif os.getenv('API_TIMEOUT') and os.getenv('API_TIMEOUT').strip():
            timeout_str = os.getenv('API_TIMEOUT').strip()
        else:
            timeout_str = '60'
        
        try:
            self.API_TIMEOUT = int(timeout_str)
            if self.API_TIMEOUT <= 0:
                raise ValueError("è¶…æ—¶æ—¶é—´å¿…é¡»å¤§äº0")
        except (ValueError, TypeError) as e:
            logger.warning(f"æ— æ•ˆçš„APIè¶…æ—¶å€¼: {timeout_str}ï¼Œé”™è¯¯: {e}ï¼Œä½¿ç”¨é»˜è®¤å€¼60ç§’")
            self.API_TIMEOUT = 60
        
        logger.info(f"AIAnalyzeråˆå§‹åŒ–å®Œæˆ: URL={self.API_URL}, MODEL={self.API_MODEL}, TIMEOUT={self.API_TIMEOUT}")
        
        # é¢„è®¾å¯¹è¯æç¤ºè¯
        self.conversation_prompts = [
            "è¯·è¯¦ç»†è§£é‡Šä¸€ä¸‹è¿™ä¸ªåˆ†æç»“æœä¸­çš„æŠ€æœ¯æŒ‡æ ‡å«ä¹‰",
            "åŸºäºå½“å‰åˆ†æï¼Œæ‚¨è®¤ä¸ºè¿™åªè‚¡ç¥¨çš„é£é™©ç‚¹åœ¨å“ªé‡Œï¼Ÿ",
            "èƒ½å¦åˆ†æä¸€ä¸‹è¿™åªè‚¡ç¥¨çš„æ”¯æ’‘ä½å’Œå‹åŠ›ä½ï¼Ÿ",
            "ä»æŠ€æœ¯é¢æ¥çœ‹ï¼Œè¿™åªè‚¡ç¥¨é€‚åˆä»€ä¹ˆç±»å‹çš„æŠ•èµ„è€…ï¼Ÿ",
            "è¯·åˆ†æä¸€ä¸‹æˆäº¤é‡å˜åŒ–å¯¹è‚¡ä»·çš„å½±å“",
            "åŸºäºRSIæŒ‡æ ‡ï¼Œå½“å‰æ˜¯å¦é€‚åˆä¹°å…¥æˆ–å–å‡ºï¼Ÿ",
            "èƒ½å¦é¢„æµ‹ä¸€ä¸‹è¿™åªè‚¡ç¥¨çš„çŸ­æœŸèµ°åŠ¿ï¼Ÿ",
            "è¯·è§£é‡Šä¸€ä¸‹MACDæŒ‡æ ‡åœ¨å½“å‰åˆ†æä¸­çš„ä½œç”¨",
            "ä»é£é™©æ”¶ç›Šæ¯”æ¥çœ‹ï¼Œè¿™åªè‚¡ç¥¨å€¼å¾—æŠ•èµ„å—ï¼Ÿ",
            "èƒ½å¦åˆ†æä¸€ä¸‹è¿™åªè‚¡ç¥¨ä¸åŒè¡Œä¸šå…¶ä»–è‚¡ç¥¨çš„å¯¹æ¯”ï¼Ÿ",
            "è¯·è¯¦ç»†è¯´æ˜ä¸€ä¸‹æ­¢æŸä½çš„è®¾ç½®é€»è¾‘",
            "åŸºäºå½“å‰æŠ€æœ¯æŒ‡æ ‡ï¼Œæ‚¨å»ºè®®çš„ä»“ä½ç®¡ç†ç­–ç•¥æ˜¯ä»€ä¹ˆï¼Ÿ",
            "èƒ½å¦åˆ†æä¸€ä¸‹è¿™åªè‚¡ç¥¨åœ¨ä¸åŒå¸‚åœºç¯å¢ƒä¸‹çš„è¡¨ç°ï¼Ÿ",
            "è¯·è§£é‡Šä¸€ä¸‹å¸ƒæ—å¸¦æŒ‡æ ‡åœ¨å½“å‰åˆ†æä¸­çš„æ„ä¹‰",
            "åŸºäºæŠ€æœ¯åˆ†æï¼Œæ‚¨è®¤ä¸ºè¿™åªè‚¡ç¥¨çš„ä¸­é•¿æœŸæŠ•èµ„ä»·å€¼å¦‚ä½•ï¼Ÿ"
        ]
    
    def get_random_conversation_prompt(self) -> str:
        """è·å–éšæœºçš„å¯¹è¯æç¤ºè¯"""
        import random
        return random.choice(self.conversation_prompts)

    async def get_completion(self, prompt: str, stream: bool = False):
        """
        ä½¿ç”¨å½“å‰æ¨¡å‹ä¸å¯†é’¥æ‰§è¡Œè¡¥å…¨ã€‚
        
        Args:
            prompt: æç¤ºè¯
            stream: æ˜¯å¦æµå¼è¾“å‡ºã€‚å¦‚æœä¸ºTrueï¼Œè¿”å›å¼‚æ­¥ç”Ÿæˆå™¨ï¼›å¦‚æœä¸ºFalseï¼Œè¿”å›å­—ç¬¦ä¸²
        
        Returns:
            str (å½“stream=False) æˆ– AsyncGenerator[str, None] (å½“stream=True)
        """
        api_url = APIUtils.format_api_url(self.API_URL)
        if not self.API_KEY or self.API_KEY.strip() == "":
            raise RuntimeError("API_KEYæœªé…ç½®æˆ–ä¸ºç©º")
        headers = {
            "Content-Type": "application/json",
            "Authorization": f"Bearer {self.API_KEY.strip()}"
        }
        request_data = {
            "model": self.API_MODEL,
            "messages": [{"role": "user", "content": prompt}],
            "temperature": 0.7,
            "stream": stream
        }
        
        if not stream:
            # éæµå¼ï¼šä¸€æ¬¡æ€§è¿”å›å®Œæ•´æ–‡æœ¬
            async with httpx.AsyncClient(timeout=self.API_TIMEOUT) as client:
                response = await client.post(api_url, json=request_data, headers=headers)
                if response.status_code != 200:
                    try:
                        data = response.json()
                        msg = data.get('error', {}).get('message', str(data))
                    except Exception:
                        msg = response.text
                    raise RuntimeError(f"APIè¯·æ±‚å¤±è´¥: {response.status_code} - {msg}")
                data = response.json()
                choices = data.get("choices", [])
                if not choices:
                    logger.error(f"APIå“åº”ä¸­æ²¡æœ‰choices: {data}")
                    raise RuntimeError(f"APIè¿”å›äº†ç©ºçš„å“åº”")
                content = choices[0].get("message", {}).get("content", "")
                if not content:
                    logger.error(f"APIå“åº”ä¸­æ²¡æœ‰å†…å®¹: {data}")
                    raise RuntimeError(f"APIè¿”å›äº†ç©ºçš„åˆ†æå†…å®¹")
                return content
        else:
            # æµå¼ï¼šè¿”å›å¼‚æ­¥ç”Ÿæˆå™¨
            return self._stream_completion(api_url, request_data, headers)
    
    async def _stream_completion(self, api_url: str, request_data: dict, headers: dict):
        """
        æµå¼è¡¥å…¨çš„å†…éƒ¨å®ç°
        Yields: (content_chunk, usage_info) å…ƒç»„
        """
        async with httpx.AsyncClient(timeout=self.API_TIMEOUT) as client:
            async with client.stream('POST', api_url, json=request_data, headers=headers) as response:
                if response.status_code != 200:
                    error_text = await response.aread()
                    try:
                        data = response.json()
                        msg = data.get('error', {}).get('message', str(data))
                    except Exception:
                        msg = error_text.decode('utf-8')
                    raise RuntimeError(f"APIè¯·æ±‚å¤±è´¥: {response.status_code} - {msg}")
                
                usage_info = None
                async for line in response.aiter_lines():
                    if not line.strip():
                        continue
                    
                    # å¤„ç† SSE æ ¼å¼ï¼šdata: {...}
                    if line.startswith('data: '):
                        line = line[6:]
                    
                    # è·³è¿‡ [DONE] æ ‡è®°
                    if line.strip() == '[DONE]':
                        break
                    
                    try:
                        chunk_data = json.loads(line)
                        delta = chunk_data.get('choices', [{}])[0].get('delta', {})
                        content = delta.get('content', '')
                        
                        # æå–usageä¿¡æ¯ï¼ˆé€šå¸¸åœ¨æœ€åä¸€ä¸ªchunkä¸­ï¼‰
                        if 'usage' in chunk_data:
                            usage_info = chunk_data['usage']
                        
                        if content:
                            yield (content, usage_info)
                    except json.JSONDecodeError:
                        # å¿½ç•¥æ— æ³•è§£æçš„è¡Œ
                        continue
                
                # å¦‚æœæœ‰usageä¿¡æ¯ä½†æœ€åæ²¡æœ‰å†…å®¹ï¼Œå•ç‹¬yieldä¸€æ¬¡
                if usage_info:
                    yield ('', usage_info)
    
    async def get_ai_analysis(self, df: pd.DataFrame, stock_code: str, market_type: str = 'A', stream: bool = False, analysis_days: int = 30, portfolio_context: Optional[str] = None) -> AsyncGenerator[str, None]:
        """
        å¯¹è‚¡ç¥¨æ•°æ®è¿›è¡ŒAIåˆ†æ
        
        Args:
            df: åŒ…å«æŠ€æœ¯æŒ‡æ ‡çš„DataFrame
            stock_code: è‚¡ç¥¨ä»£ç 
            market_type: å¸‚åœºç±»å‹ï¼Œé»˜è®¤ä¸º'A'è‚¡
            stream: æ˜¯å¦ä½¿ç”¨æµå¼å“åº”
            analysis_days: AIåˆ†æä½¿ç”¨çš„å¤©æ•°ï¼Œé»˜è®¤30å¤©
            portfolio_context: ç”¨æˆ·æŒä»“ä¿¡æ¯ï¼ˆå¯é€‰ï¼‰ï¼Œå°†æ·»åŠ åˆ°åˆ†ææç¤ºè¯ä¸­
            
        Returns:
            å¼‚æ­¥ç”Ÿæˆå™¨ï¼Œç”Ÿæˆåˆ†æç»“æœå­—ç¬¦ä¸²
        """
        try:
            logger.info(f"å¼€å§‹AIåˆ†æ {stock_code}, æµå¼æ¨¡å¼: {stream}")
            
            # æå–å…³é”®æŠ€æœ¯æŒ‡æ ‡
            latest_data = df.iloc[-1]
            
            # è®¡ç®—æŠ€æœ¯æŒ‡æ ‡
            rsi = latest_data.get('RSI')
            price = latest_data.get('Close')
            price_change = latest_data.get('Change')
            
            # ç¡®å®šMAè¶‹åŠ¿
            ma_trend = 'UP' if latest_data.get('MA5', 0) > latest_data.get('MA20', 0) else 'DOWN'
            
            # ç¡®å®šMACDä¿¡å·
            macd = latest_data.get('MACD', 0)
            macd_signal = latest_data.get('MACD_Signal', 0)
            macd_signal_type = 'BUY' if macd > macd_signal else 'SELL'
            
            # ç¡®å®šæˆäº¤é‡çŠ¶æ€
            volume_ratio = latest_data.get('Volume_Ratio', 1)
            volume_status = 'HIGH' if volume_ratio > 1.5 else ('LOW' if volume_ratio < 0.5 else 'NORMAL')
            
            # AI åˆ†æå†…å®¹
            # è·å–æŒ‡å®šå¤©æ•°çš„è‚¡ç¥¨æ•°æ®è®°å½•
            recent_df = df.tail(analysis_days).copy()
            recent_df.reset_index(inplace=True)
            # ç»Ÿä¸€æŠŠç¬¬ä¸€ä¸ªåˆ—åï¼ˆåŸindexï¼‰é‡å‘½åä¸º 'date'
            recent_df.rename(columns={recent_df.columns[0]: 'date'}, inplace=True)
            # ç¡®ä¿ 'date' åˆ—ä¸ºå­—ç¬¦ä¸²æ ¼å¼
            if pd.api.types.is_datetime64_any_dtype(recent_df['date']):
                recent_df['date'] = recent_df['date'].dt.strftime('%Y-%m-%d')
            else:
                try:
                    recent_df['date'] = pd.to_datetime(recent_df['date']).dt.strftime('%Y-%m-%d')
                except Exception:
                    recent_df['date'] = recent_df['date'].astype(str)
            
            recent_data = recent_df.to_dict('records')
            logger.debug(f"recent_data for chart: {recent_data}")
            
            # åŒ…å«trend, volatility, volume_trend, rsi_levelçš„å­—å…¸
            technical_summary = {
                'trend': 'upward' if df.iloc[-1]['MA5'] > df.iloc[-1]['MA20'] else 'downward',
                'volatility': f"{df.iloc[-1]['Volatility']:.2f}%",
                'volume_trend': 'increasing' if df.iloc[-1]['Volume_Ratio'] > 1 else 'decreasing',
                'rsi_level': df.iloc[-1]['RSI']
            }
            
            # æ ¹æ®å¸‚åœºç±»å‹è°ƒæ•´åˆ†ææç¤º
            if market_type in ['ETF', 'LOF']:
                prompt = f"""
                åˆ†æåŸºé‡‘ {stock_code}ï¼š

                æŠ€æœ¯æŒ‡æ ‡æ¦‚è¦ï¼š
                {technical_summary}
                
                è¿‘{analysis_days}æ—¥äº¤æ˜“æ•°æ®ï¼š
                {recent_data}
                
                è¯·æä¾›ï¼š
                1. å‡€å€¼èµ°åŠ¿åˆ†æï¼ˆåŒ…å«æ”¯æ’‘ä½å’Œå‹åŠ›ä½ï¼‰
                2. æˆäº¤é‡åˆ†æåŠå…¶å¯¹å‡€å€¼çš„å½±å“
                3. é£é™©è¯„ä¼°ï¼ˆåŒ…å«æ³¢åŠ¨ç‡å’ŒæŠ˜æº¢ä»·åˆ†æï¼‰
                4. çŸ­æœŸå’Œä¸­æœŸå‡€å€¼é¢„æµ‹
                5. å…³é”®ä»·æ ¼ä½åˆ†æ
                6. ç”³è´­èµå›å»ºè®®ï¼ˆåŒ…å«æ­¢æŸä½ï¼‰
                
                è¯·åŸºäºæŠ€æœ¯æŒ‡æ ‡å’Œå¸‚åœºè¡¨ç°è¿›è¡Œåˆ†æï¼Œç»™å‡ºå…·ä½“æ•°æ®æ”¯æŒã€‚
                """
            elif market_type == 'US':
                prompt = f"""
                åˆ†æç¾è‚¡ {stock_code}ï¼š

                æŠ€æœ¯æŒ‡æ ‡æ¦‚è¦ï¼š
                {technical_summary}
                
                è¿‘{analysis_days}æ—¥äº¤æ˜“æ•°æ®ï¼š
                {recent_data}
                
                è¯·æä¾›ï¼š
                1. è¶‹åŠ¿åˆ†æï¼ˆåŒ…å«æ”¯æ’‘ä½å’Œå‹åŠ›ä½ï¼Œç¾å…ƒè®¡ä»·ï¼‰
                2. æˆäº¤é‡åˆ†æåŠå…¶å«ä¹‰
                3. é£é™©è¯„ä¼°ï¼ˆåŒ…å«æ³¢åŠ¨ç‡å’Œç¾è‚¡å¸‚åœºç‰¹æœ‰é£é™©ï¼‰
                4. çŸ­æœŸå’Œä¸­æœŸç›®æ ‡ä»·ä½ï¼ˆç¾å…ƒï¼‰
                5. å…³é”®æŠ€æœ¯ä½åˆ†æ
                6. å…·ä½“äº¤æ˜“å»ºè®®ï¼ˆåŒ…å«æ­¢æŸä½ï¼‰
                
                è¯·åŸºäºæŠ€æœ¯æŒ‡æ ‡å’Œç¾è‚¡å¸‚åœºç‰¹ç‚¹è¿›è¡Œåˆ†æï¼Œç»™å‡ºå…·ä½“æ•°æ®æ”¯æŒã€‚
                """
            elif market_type == 'HK':
                prompt = f"""
                åˆ†ææ¸¯è‚¡ {stock_code}ï¼š

                æŠ€æœ¯æŒ‡æ ‡æ¦‚è¦ï¼š
                {technical_summary}
                
                è¿‘{analysis_days}æ—¥äº¤æ˜“æ•°æ®ï¼š
                {recent_data}
                
                è¯·æä¾›ï¼š
                1. è¶‹åŠ¿åˆ†æï¼ˆåŒ…å«æ”¯æ’‘ä½å’Œå‹åŠ›ä½ï¼Œæ¸¯å¸è®¡ä»·ï¼‰
                2. æˆäº¤é‡åˆ†æåŠå…¶å«ä¹‰
                3. é£é™©è¯„ä¼°ï¼ˆåŒ…å«æ³¢åŠ¨ç‡å’Œæ¸¯è‚¡å¸‚åœºç‰¹æœ‰é£é™©ï¼‰
                4. çŸ­æœŸå’Œä¸­æœŸç›®æ ‡ä»·ä½ï¼ˆæ¸¯å¸ï¼‰
                5. å…³é”®æŠ€æœ¯ä½åˆ†æ
                6. å…·ä½“äº¤æ˜“å»ºè®®ï¼ˆåŒ…å«æ­¢æŸä½ï¼‰
                
                è¯·åŸºäºæŠ€æœ¯æŒ‡æ ‡å’Œæ¸¯è‚¡å¸‚åœºç‰¹ç‚¹è¿›è¡Œåˆ†æï¼Œç»™å‡ºå…·ä½“æ•°æ®æ”¯æŒã€‚
                """
            else:  # Aè‚¡
                prompt = f"""
                åˆ†æAè‚¡ {stock_code}ï¼š

                æŠ€æœ¯æŒ‡æ ‡æ¦‚è¦ï¼š
                {technical_summary}
                
                è¿‘{analysis_days}æ—¥äº¤æ˜“æ•°æ®ï¼š
                {recent_data}
                
                è¯·æä¾›ï¼š
                1. è¶‹åŠ¿åˆ†æï¼ˆåŒ…å«æ”¯æ’‘ä½å’Œå‹åŠ›ä½ï¼‰
                2. æˆäº¤é‡åˆ†æåŠå…¶å«ä¹‰
                3. é£é™©è¯„ä¼°ï¼ˆåŒ…å«æ³¢åŠ¨ç‡åˆ†æï¼‰
                4. çŸ­æœŸå’Œä¸­æœŸç›®æ ‡ä»·ä½
                5. å…³é”®æŠ€æœ¯ä½åˆ†æ
                6. å…·ä½“äº¤æ˜“å»ºè®®ï¼ˆåŒ…å«æ­¢æŸä½ï¼‰
                
                è¯·åŸºäºæŠ€æœ¯æŒ‡æ ‡å’ŒAè‚¡å¸‚åœºç‰¹ç‚¹è¿›è¡Œåˆ†æï¼Œç»™å‡ºå…·ä½“æ•°æ®æ”¯æŒã€‚
                """
            
            if portfolio_context:
                logger.info(f"Add portfolio (len: {len(portfolio_context)})")
                prompt += f"\n\n{'='*50}\nğŸ“Š æˆ‘çš„æŒä»“æƒ…å†µ\n{'='*50}\n{portfolio_context}"
            else:
                logger.debug(f"portfolio_context not provided")
            
            # æ ¼å¼åŒ–API URL
            api_url = APIUtils.format_api_url(self.API_URL)
            
            # å‡†å¤‡è¯·æ±‚æ•°æ®
            request_data = {
                "model": self.API_MODEL,
                "messages": [{"role": "user", "content": prompt}],
                "temperature": 0.7,
                "stream": stream
            }
            
            # æ£€æŸ¥API_KEYæ˜¯å¦ä¸ºç©º
            if not self.API_KEY or self.API_KEY.strip() == "":
                logger.error("API_KEYä¸ºç©ºï¼Œæ— æ³•è¿›è¡Œè‚¡ç¥¨åˆ†æ")
                yield json.dumps({
                    "stock_code": stock_code,
                    "error": "API_KEYæœªé…ç½®æˆ–ä¸ºç©ºï¼Œè¯·æ£€æŸ¥APIé…ç½®",
                    "status": "error"
                }, ensure_ascii=False)
                return
            
            # å‡†å¤‡è¯·æ±‚å¤´
            headers = {
                "Content-Type": "application/json",
                "Authorization": f"Bearer {self.API_KEY.strip()}"
            }
            
            # è·å–å½“å‰æ—¥æœŸä½œä¸ºåˆ†ææ—¥æœŸ
            analysis_date = datetime.now().strftime("%Y-%m-%d")
            
            # å¼‚æ­¥è¯·æ±‚API
            async with httpx.AsyncClient(timeout=self.API_TIMEOUT) as client:
                # è®°å½•è¯·æ±‚
                logger.debug(f"å‘é€AIè¯·æ±‚: URL={api_url}, MODEL={self.API_MODEL}, STREAM={stream}")
                logger.debug(f"å®Œæ•´çš„AIè¯·æ±‚Prompt for {stock_code}:\n{prompt}")
                
                # å…ˆå‘é€æŠ€æœ¯æŒ‡æ ‡æ•°æ®
                yield json.dumps({
                    "stock_code": stock_code,
                    "status": "analyzing",
                    "chart_data": recent_data
                }, ensure_ascii=False)
                
                if stream:
                    # æµå¼å“åº”å¤„ç†
                    async with client.stream("POST", api_url, json=request_data, headers=headers) as response:
                        if response.status_code != 200:
                            error_text = await response.aread()
                            error_data = json.loads(error_text)
                            error_message = error_data.get('error', {}).get('message', 'æœªçŸ¥é”™è¯¯')
                            logger.error(f"AI APIè¯·æ±‚å¤±è´¥: {response.status_code} - {error_message}")
                            yield json.dumps({
                                "stock_code": stock_code,
                                "error": f"APIè¯·æ±‚å¤±è´¥: {error_message}",
                                "status": "error"
                            })
                            return
                            
                        # å¤„ç†æµå¼å“åº”
                        buffer = ""
                        collected_messages = []
                        chunk_count = 0
                        usage_info = None  # æ”¶é›†usageä¿¡æ¯
                        
                        async for chunk in response.aiter_text():
                            if chunk:
                                # åˆ†å‰²å¤šè¡Œå“åº”ï¼ˆå¤„ç†æŸäº›APIå¯èƒ½åœ¨ä¸€ä¸ªchunkä¸­è¿”å›å¤šè¡Œï¼‰
                                lines = chunk.strip().split('\n')
                                for line in lines:
                                    line = line.strip()
                                    if not line:
                                        continue
                                        
                                    # å¤„ç†ä»¥data:å¼€å¤´çš„è¡Œ
                                    if line.startswith("data: "):
                                        line = line[6:]  # å»é™¤"data: "å‰ç¼€
                                     
                                    if line == "[DONE]":
                                        logger.debug("æ”¶åˆ°æµç»“æŸæ ‡è®° [DONE]")
                                        continue
                                        
                                    try:
                                        # å¤„ç†ç‰¹æ®Šé”™è¯¯æƒ…å†µ
                                        if "error" in line.lower():
                                            error_msg = line
                                            try:
                                                error_data = json.loads(line)
                                                error_msg = error_data.get("error", line)
                                            except:
                                                pass
                                            
                                            logger.error(f"æµå¼å“åº”ä¸­æ”¶åˆ°é”™è¯¯: {error_msg}")
                                            yield json.dumps({
                                                "stock_code": stock_code,
                                                "error": f"æµå¼å“åº”é”™è¯¯: {error_msg}",
                                                "status": "error"
                                            })
                                            continue
                                        
                                        # å°è¯•è§£æJSON
                                        chunk_data = json.loads(line)
                                        
                                        # è·å–choicesæ•°ç»„ï¼Œç¡®ä¿ä¸ä¸ºç©º
                                        choices = chunk_data.get("choices", [])
                                        if not choices:
                                            logger.debug("æ”¶åˆ°ç©ºçš„choicesæ•°ç»„ï¼Œè·³è¿‡")
                                            # å³ä½¿choicesä¸ºç©ºï¼Œä¹Ÿæ£€æŸ¥æ˜¯å¦æœ‰usageä¿¡æ¯
                                            if 'usage' in chunk_data:
                                                usage_info = chunk_data['usage']
                                                if usage_info:
                                                    logger.debug(f"æ”¶åˆ°usageä¿¡æ¯: {usage_info}")
                                            continue
                                        
                                        # æ£€æŸ¥æ˜¯å¦æœ‰finish_reason
                                        finish_reason = choices[0].get("finish_reason")
                                        if finish_reason == "stop":
                                            logger.debug("æ”¶åˆ°finish_reason=stopï¼Œæµç»“æŸ")
                                            # æµç»“æŸæ—¶ä¹Ÿæ£€æŸ¥usageä¿¡æ¯
                                            if 'usage' in chunk_data:
                                                usage_info = chunk_data['usage']
                                                if usage_info:
                                                    logger.debug(f"æ”¶åˆ°usageä¿¡æ¯: {usage_info}")
                                            continue
                                        
                                        # æå–usageä¿¡æ¯ï¼ˆé€šå¸¸åœ¨æœ€åä¸€ä¸ªchunkä¸­ï¼‰
                                        if 'usage' in chunk_data:
                                            usage_info = chunk_data['usage']
                                            if usage_info:
                                                logger.debug(f"æ”¶åˆ°usageä¿¡æ¯: {usage_info}")
                                        
                                        # è·å–deltaå†…å®¹
                                        delta = choices[0].get("delta", {})
                                        
                                        # æ£€æŸ¥deltaæ˜¯å¦ä¸ºç©ºå¯¹è±¡
                                        if not delta or delta == {}:
                                            logger.debug("æ”¶åˆ°ç©ºçš„deltaå¯¹è±¡ï¼Œè·³è¿‡")
                                            continue
                                        
                                        content = delta.get("content", "")
                                        
                                        if content:
                                            chunk_count += 1
                                            buffer += content
                                            collected_messages.append(content)
                                            
                                            # ç›´æ¥å‘é€æ¯ä¸ªå†…å®¹ç‰‡æ®µï¼Œä¸ç´¯ç§¯
                                            yield json.dumps({
                                                "stock_code": stock_code,
                                                "ai_analysis_chunk": content,
                                                "status": "analyzing"
                                            })
                                    except json.JSONDecodeError:
                                        # è®°å½•è§£æé”™è¯¯å¹¶å°è¯•æ¢å¤
                                        logger.error(f"JSONè§£æé”™è¯¯ï¼Œå—å†…å®¹: {line}")
                                        
                                        # å¦‚æœæ˜¯ç‰¹å®šé”™è¯¯æ¨¡å¼ï¼Œå¤„ç†å®ƒ
                                        if "streaming failed after retries" in line.lower():
                                            logger.error("æ£€æµ‹åˆ°æµå¼ä¼ è¾“å¤±è´¥")
                                            yield json.dumps({
                                                "stock_code": stock_code,
                                                "error": "æµå¼ä¼ è¾“å¤±è´¥ï¼Œè¯·ç¨åé‡è¯•",
                                                "status": "error"
                                            })
                                            return
                                        continue
                        
                        logger.info(f"AIæµå¼å¤„ç†å®Œæˆï¼Œå…±æ”¶åˆ° {chunk_count} ä¸ªå†…å®¹ç‰‡æ®µï¼Œæ€»é•¿åº¦: {len(buffer)}")
                        
                        # å¦‚æœbufferä¸ä¸ºç©ºä¸”ä¸ä»¥æ¢è¡Œç¬¦ç»“æŸï¼Œå‘é€ä¸€ä¸ªæ¢è¡Œç¬¦
                        if buffer and not buffer.endswith('\n'):
                            logger.debug("å‘é€æ¢è¡Œç¬¦")
                            yield json.dumps({
                                "stock_code": stock_code,
                                "ai_analysis_chunk": "\n",
                                "status": "analyzing"
                            })
                        
                        # å®Œæ•´çš„åˆ†æå†…å®¹
                        full_content = buffer
                        logger.debug(f"full_content: {full_content}")
                        # logger.debug(f"collected_messages: {collected_messages}")
                        
                        # å°è¯•ä»åˆ†æå†…å®¹ä¸­æå–æŠ•èµ„å»ºè®®
                        recommendation = self._extract_recommendation(full_content)
                        
                        # è®¡ç®—åˆ†æè¯„åˆ†
                        score = self._calculate_analysis_score(full_content, technical_summary)
                        
                        # å‘é€å®ŒæˆçŠ¶æ€å’Œè¯„åˆ†ã€å»ºè®®
                        completion_data = {
                            "stock_code": stock_code,
                            "status": "completed",
                            "score": score,
                            "recommendation": recommendation
                        }
                        
                        # æ·»åŠ tokenä½¿ç”¨ä¿¡æ¯
                        if usage_info:
                            completion_data["token_usage"] = usage_info
                            logger.info(f"æ ‡å‡†åˆ†æå®Œæˆï¼Œtokenä½¿ç”¨ï¼ˆç²¾ç¡®ï¼‰: {usage_info}")
                        else:
                            # APIä¸è¿”å›usageï¼Œä½¿ç”¨å­—ç¬¦æ•°ä¼°ç®—
                            prompt_chars = len(prompt)
                            output_chars = len(buffer)
                            estimated_tokens = (prompt_chars + output_chars) // 3
                            completion_data["token_usage"] = {
                                "estimated": True,
                                "total_tokens": estimated_tokens,
                                "prompt_chars": prompt_chars,
                                "output_chars": output_chars
                            }
                            logger.info(f"æ ‡å‡†åˆ†æå®Œæˆï¼Œä¼°ç®—tokenä½¿ç”¨: ~{estimated_tokens} (è¾“å…¥{prompt_chars}å­—ç¬¦ + è¾“å‡º{output_chars}å­—ç¬¦)")
                        
                        yield json.dumps(completion_data)
                else:
                    # éæµå¼å“åº”å¤„ç†
                    response = await client.post(api_url, json=request_data, headers=headers)
                    
                    if response.status_code != 200:
                        error_data = response.json()
                        error_message = error_data.get('error', {}).get('message', 'æœªçŸ¥é”™è¯¯')
                        logger.error(f"AI APIè¯·æ±‚å¤±è´¥: {response.status_code} - {error_message}")
                        yield json.dumps({
                            "stock_code": stock_code,
                            "error": f"APIè¯·æ±‚å¤±è´¥: {error_message}",
                            "status": "error"
                        })
                        return
                    
                    response_data = response.json()
                    
                    # å®‰å…¨åœ°æå–åˆ†æå†…å®¹
                    choices = response_data.get("choices", [])
                    if not choices:
                        logger.error(f"APIå“åº”ä¸­æ²¡æœ‰choices: {response_data}")
                        yield json.dumps({
                            "stock_code": stock_code,
                            "error": "APIè¿”å›äº†ç©ºçš„å“åº”",
                            "status": "error"
                        })
                        return
                    
                    analysis_text = choices[0].get("message", {}).get("content", "")
                    if not analysis_text:
                        logger.error(f"APIå“åº”ä¸­æ²¡æœ‰å†…å®¹: {response_data}")
                        yield json.dumps({
                            "stock_code": stock_code,
                            "error": "APIè¿”å›äº†ç©ºçš„åˆ†æå†…å®¹",
                            "status": "error"
                        })
                        return
                    
                    # æå–usageä¿¡æ¯
                    usage_info = response_data.get('usage')
                    
                    # å°è¯•ä»åˆ†æå†…å®¹ä¸­æå–æŠ•èµ„å»ºè®®
                    recommendation = self._extract_recommendation(analysis_text)
                    
                    # è®¡ç®—åˆ†æè¯„åˆ†
                    score = self._calculate_analysis_score(analysis_text, technical_summary)
                    
                    # å‘é€å®Œæ•´çš„åˆ†æç»“æœ
                    completion_data = {
                        "stock_code": stock_code,
                        "status": "completed",
                        "analysis": analysis_text,
                        "score": score,
                        "recommendation": recommendation,
                        "rsi": rsi,
                        "price": price,
                        "price_change": price_change,
                        "ma_trend": ma_trend,
                        "macd_signal": macd_signal_type,
                        "volume_status": volume_status,
                        "analysis_date": analysis_date
                    }
                    
                    # æ·»åŠ tokenä½¿ç”¨ä¿¡æ¯
                    if usage_info:
                        completion_data["token_usage"] = usage_info
                        logger.info(f"æ ‡å‡†åˆ†æå®Œæˆï¼ˆéæµå¼ï¼‰ï¼Œtokenä½¿ç”¨ï¼ˆç²¾ç¡®ï¼‰: {usage_info}")
                    else:
                        # APIä¸è¿”å›usageï¼Œä½¿ç”¨å­—ç¬¦æ•°ä¼°ç®—
                        prompt_chars = len(prompt)
                        output_chars = len(analysis_text)
                        estimated_tokens = (prompt_chars + output_chars) // 3
                        completion_data["token_usage"] = {
                            "estimated": True,
                            "total_tokens": estimated_tokens,
                            "prompt_chars": prompt_chars,
                            "output_chars": output_chars
                        }
                        logger.info(f"æ ‡å‡†åˆ†æå®Œæˆï¼ˆéæµå¼ï¼‰ï¼Œä¼°ç®—tokenä½¿ç”¨: ~{estimated_tokens}")
                    
                    yield json.dumps(completion_data)
                    
        except Exception as e:
            logger.error(f"AIåˆ†æå‡ºé”™: {str(e)}", exc_info=True)
            yield json.dumps({
                "stock_code": stock_code,
                "error": f"åˆ†æå‡ºé”™: {str(e)}",
                "status": "error"
            })
            
    def _extract_recommendation(self, analysis_text: str) -> str:
        """ä»åˆ†ææ–‡æœ¬ä¸­æå–æŠ•èµ„å»ºè®®"""
        # æŸ¥æ‰¾æŠ•èµ„å»ºè®®éƒ¨åˆ†
        investment_advice_pattern = r"##\s*æŠ•èµ„å»ºè®®\s*\n(.*?)(?:\n##|\Z)"
        match = re.search(investment_advice_pattern, analysis_text, re.DOTALL)
        
        if match:
            advice_text = match.group(1).strip()
            
            # æå–å…³é”®å»ºè®®
            if "ä¹°å…¥" in advice_text or "å¢æŒ" in advice_text:
                return "ä¹°å…¥"
            elif "å–å‡º" in advice_text or "å‡æŒ" in advice_text:
                return "å–å‡º"
            elif "æŒæœ‰" in advice_text:
                return "æŒæœ‰"
            else:
                return "è§‚æœ›"
        
        return "è§‚æœ›"  # é»˜è®¤å»ºè®®
        
    def _calculate_analysis_score(self, analysis_text: str, technical_summary: dict) -> int:
        """è®¡ç®—åˆ†æè¯„åˆ†"""
        score = 50  # åŸºç¡€åˆ†æ•°
        
        # æ ¹æ®æŠ€æœ¯æŒ‡æ ‡è°ƒæ•´åˆ†æ•°
        if technical_summary['trend'] == 'upward':
            score += 10
        else:
            score -= 10
            
        if technical_summary['volume_trend'] == 'increasing':
            score += 5
        else:
            score -= 5
            
        rsi = technical_summary['rsi_level']
        if rsi < 30:  # è¶…å–
            score += 15
        elif rsi > 70:  # è¶…ä¹°
            score -= 15
            
        # æ ¹æ®åˆ†ææ–‡æœ¬ä¸­çš„å…³é”®è¯è°ƒæ•´åˆ†æ•°
        if "å¼ºçƒˆä¹°å…¥" in analysis_text or "æ˜¾è‘—ä¸Šæ¶¨" in analysis_text:
            score += 20
        elif "ä¹°å…¥" in analysis_text or "çœ‹æ¶¨" in analysis_text:
            score += 10
        elif "å¼ºçƒˆå–å‡º" in analysis_text or "æ˜¾è‘—ä¸‹è·Œ" in analysis_text:
            score -= 20
        elif "å–å‡º" in analysis_text or "çœ‹è·Œ" in analysis_text:
            score -= 10
            
        # ç¡®ä¿åˆ†æ•°åœ¨0-100èŒƒå›´å†…
        return max(0, min(100, score))
    
    def _truncate_json_for_logging(self, json_obj, max_length=500):
        """æˆªæ–­JSONå¯¹è±¡ç”¨äºæ—¥å¿—è®°å½•"""
        json_str = json.dumps(json_obj, ensure_ascii=False)
        if len(json_str) > max_length:
            return json_str[:max_length] + "..."
        return json_str

    async def get_conversation_response(self, 
                                      conversation_messages: List[Dict[str, str]], 
                                      analysis_context: Dict[str, Any],
                                      user_message: str,
                                      stream: bool = False) -> AsyncGenerator[str, None]:
        """
        å¤„ç†AIå¯¹è¯å›å¤
        
        Args:
            conversation_messages: å†å²å¯¹è¯æ¶ˆæ¯åˆ—è¡¨
            analysis_context: åŸå§‹åˆ†æç»“æœä¸Šä¸‹æ–‡
            user_message: ç”¨æˆ·å½“å‰æ¶ˆæ¯
            stream: æ˜¯å¦ä½¿ç”¨æµå¼å“åº”
            
        Returns:
            å¼‚æ­¥ç”Ÿæˆå™¨ï¼Œç”ŸæˆAIå›å¤
        """
        try:
            logger.info(f"å¼€å§‹å¤„ç†å¯¹è¯è¯·æ±‚ï¼Œæ¶ˆæ¯æ•°é‡: {len(conversation_messages)}")
            
            # æ„å»ºç³»ç»Ÿæç¤ºè¯
            system_prompt = self._build_conversation_system_prompt(analysis_context)
            
            # æ„å»ºæ¶ˆæ¯å†å²
            messages = [{"role": "system", "content": system_prompt}]
            
            # æ·»åŠ å†å²å¯¹è¯æ¶ˆæ¯
            for msg in conversation_messages:
                messages.append({
                    "role": msg["role"],
                    "content": msg["content"]
                })
            
            # æ·»åŠ ç”¨æˆ·å½“å‰æ¶ˆæ¯
            messages.append({"role": "user", "content": user_message})
            
            # æ ¼å¼åŒ–API URL
            api_url = APIUtils.format_api_url(self.API_URL)
            
            # å‡†å¤‡è¯·æ±‚æ•°æ®
            request_data = {
                "model": self.API_MODEL,
                "messages": messages,
                "temperature": 0.7,
                "stream": stream
            }
            
            # æ£€æŸ¥API_KEYæ˜¯å¦ä¸ºç©º
            if not self.API_KEY or self.API_KEY.strip() == "":
                logger.error("API_KEYä¸ºç©ºï¼Œæ— æ³•å¤„ç†å¯¹è¯è¯·æ±‚")
                yield json.dumps({
                    "error": "API_KEYæœªé…ç½®æˆ–ä¸ºç©ºï¼Œè¯·æ£€æŸ¥APIé…ç½®",
                    "status": "error"
                })
                return
            
            # å‡†å¤‡è¯·æ±‚å¤´
            headers = {
                "Content-Type": "application/json",
                "Authorization": f"Bearer {self.API_KEY.strip()}"
            }
            
            logger.debug(f"å‘é€å¯¹è¯è¯·æ±‚: URL={api_url}, MODEL={self.API_MODEL}, STREAM={stream}")
            logger.debug(f"å¯¹è¯æ¶ˆæ¯æ•°é‡: {len(messages)}")
            
            # å¼‚æ­¥è¯·æ±‚API
            async with httpx.AsyncClient(timeout=self.API_TIMEOUT) as client:
                if stream:
                    # æµå¼å“åº”å¤„ç†
                    async with client.stream("POST", api_url, json=request_data, headers=headers) as response:
                        if response.status_code != 200:
                            error_text = await response.aread()
                            error_data = json.loads(error_text)
                            error_message = error_data.get('error', {}).get('message', 'æœªçŸ¥é”™è¯¯')
                            logger.error(f"å¯¹è¯APIè¯·æ±‚å¤±è´¥: {response.status_code} - {error_message}")
                            yield json.dumps({
                                "error": f"APIè¯·æ±‚å¤±è´¥: {error_message}",
                                "status": "error"
                            })
                            return
                            
                        # å¤„ç†æµå¼å“åº”
                        buffer = ""
                        collected_messages = []
                        
                        async for chunk in response.aiter_text():
                            if chunk:
                                # åˆ†å‰²å¤šè¡Œå“åº”
                                lines = chunk.strip().split('\n')
                                for line in lines:
                                    line = line.strip()
                                    if not line:
                                        continue
                                        
                                    # å¤„ç†ä»¥data:å¼€å¤´çš„è¡Œ
                                    if line.startswith("data: "):
                                        line = line[6:]  # å»é™¤"data: "å‰ç¼€
                                     
                                    if line == "[DONE]":
                                        logger.debug("æ”¶åˆ°æµç»“æŸæ ‡è®° [DONE]")
                                        continue
                                        
                                    try:
                                        # å¤„ç†ç‰¹æ®Šé”™è¯¯æƒ…å†µ
                                        if "error" in line.lower():
                                            error_msg = line
                                            try:
                                                error_data = json.loads(line)
                                                error_msg = error_data.get("error", line)
                                            except:
                                                pass
                                            
                                            logger.error(f"æµå¼å“åº”ä¸­æ”¶åˆ°é”™è¯¯: {error_msg}")
                                            yield json.dumps({
                                                "error": f"æµå¼å“åº”é”™è¯¯: {error_msg}",
                                                "status": "error"
                                            })
                                            continue
                                        
                                        # å°è¯•è§£æJSON
                                        chunk_data = json.loads(line)
                                        
                                        # æ£€æŸ¥æ˜¯å¦æœ‰finish_reason
                                        finish_reason = chunk_data.get("choices", [{}])[0].get("finish_reason")
                                        if finish_reason == "stop":
                                            logger.debug("æ”¶åˆ°finish_reason=stopï¼Œæµç»“æŸ")
                                            continue
                                        
                                        # è·å–deltaå†…å®¹
                                        delta = chunk_data.get("choices", [{}])[0].get("delta", {})
                                        
                                        if "content" in delta:
                                            content = delta["content"]
                                            if content is not None:  # ç¡®ä¿contentä¸æ˜¯None
                                                buffer += content
                                                collected_messages.append(content)
                                                
                                                # æµå¼è¿”å›å†…å®¹
                                                yield json.dumps({
                                                    "content": content,
                                                    "status": "streaming"
                                                })
                                            
                                    except json.JSONDecodeError as e:
                                        logger.warning(f"è§£ææµå¼å“åº”JSONå¤±è´¥: {e}, åŸå§‹æ•°æ®: {line}")
                                        continue
                                    
                        # æµå¼å“åº”å®Œæˆ
                        if buffer:
                            logger.info(f"å¯¹è¯æµå¼å“åº”å®Œæˆï¼Œæ€»é•¿åº¦: {len(buffer)}")
                            yield json.dumps({
                                "content": buffer,
                                "status": "completed"
                            })
                else:
                    # éæµå¼å“åº”å¤„ç†
                    response = await client.post(api_url, json=request_data, headers=headers)
                    
                    if response.status_code != 200:
                        error_data = response.json()
                        error_message = error_data.get('error', {}).get('message', 'æœªçŸ¥é”™è¯¯')
                        logger.error(f"å¯¹è¯APIè¯·æ±‚å¤±è´¥: {response.status_code} - {error_message}")
                        yield json.dumps({
                            "error": f"APIè¯·æ±‚å¤±è´¥: {error_message}",
                            "status": "error"
                        })
                        return
                    
                    response_data = response.json()
                    
                    # å®‰å…¨åœ°æå–å¯¹è¯å†…å®¹
                    choices = response_data.get("choices", [])
                    if not choices:
                        logger.error(f"å¯¹è¯APIå“åº”ä¸­æ²¡æœ‰choices: {response_data}")
                        yield json.dumps({
                            "error": "APIè¿”å›äº†ç©ºçš„å“åº”",
                            "status": "error"
                        })
                        return
                    
                    content = choices[0].get("message", {}).get("content", "")
                    if not content:
                        logger.error(f"å¯¹è¯APIå“åº”ä¸­æ²¡æœ‰å†…å®¹: {response_data}")
                        yield json.dumps({
                            "error": "APIè¿”å›äº†ç©ºçš„å¯¹è¯å†…å®¹",
                            "status": "error"
                        })
                        return
                    
                    logger.info(f"å¯¹è¯å“åº”å®Œæˆï¼Œé•¿åº¦: {len(content)}")
                    yield json.dumps({
                        "content": content,
                        "status": "completed"
                    })
                    
        except Exception as e:
            logger.error(f"å¤„ç†å¯¹è¯è¯·æ±‚å¤±è´¥: {str(e)}")
            logger.exception(e)
            yield json.dumps({
                "error": f"å¤„ç†å¯¹è¯è¯·æ±‚å¤±è´¥: {str(e)}",
                "status": "error"
            })

    def _build_conversation_system_prompt(self, analysis_context: Dict[str, Any]) -> str:
        """
        æ„å»ºå¯¹è¯ç³»ç»Ÿæç¤ºè¯
        
        Args:
            analysis_context: åŸå§‹åˆ†æç»“æœä¸Šä¸‹æ–‡
            
        Returns:
            ç³»ç»Ÿæç¤ºè¯å­—ç¬¦ä¸²
        """
        stock_codes = analysis_context.get("stock_codes", [])
        market_type = analysis_context.get("market_type", "A")
        analysis_result = analysis_context.get("analysis_result", {})
        ai_output = analysis_context.get("ai_output", "")
        chart_data = analysis_context.get("chart_data", {})
        
        # æ„å»ºè‚¡ç¥¨ä¿¡æ¯æ‘˜è¦
        stock_summary = []
        if analysis_result:  # æ£€æŸ¥analysis_resultæ˜¯å¦ä¸ºNone
            for code in stock_codes:
                if code in analysis_result:
                    stock_info = analysis_result[code]
                    summary = f"{code}: ä»·æ ¼{stock_info.get('price', 'N/A')}, è¯„åˆ†{stock_info.get('score', 'N/A')}, RSI{stock_info.get('rsi', 'N/A')}"
                    stock_summary.append(summary)
        
        # å¸‚åœºç±»å‹æ˜ å°„
        market_names = {
            "A": "Aè‚¡",
            "HK": "æ¸¯è‚¡", 
            "US": "ç¾è‚¡",
            "ETF": "ETFåŸºé‡‘",
            "LOF": "LOFåŸºé‡‘"
        }
        market_name = market_names.get(market_type, market_type)
        
        system_prompt = f"""
ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„è‚¡ç¥¨åˆ†æå¸ˆåŠ©æ‰‹ã€‚ç”¨æˆ·æ­£åœ¨ä¸ä½ è®¨è®ºå…³äº{market_name}çš„åˆ†æç»“æœã€‚

## åˆ†æèƒŒæ™¯ä¿¡æ¯

**åˆ†æçš„è‚¡ç¥¨**: {', '.join(stock_codes)}
**å¸‚åœºç±»å‹**: {market_name}
**åˆ†æå‘¨æœŸ**: {analysis_context.get('analysis_days', 30)}å¤©

**è‚¡ç¥¨æŠ€æœ¯æŒ‡æ ‡æ‘˜è¦**:
{chr(10).join(stock_summary) if stock_summary else 'æš‚æ— è¯¦ç»†æ•°æ®'}

**åŸå§‹AIåˆ†æç»“æœ**:
{ai_output if ai_output else 'æš‚æ— AIåˆ†æç»“æœ'}

## ä½ çš„èŒè´£

1. **åŸºäºåŸå§‹åˆ†æç»“æœ**: ä½ çš„å›ç­”åº”è¯¥åŸºäºä¸Šè¿°åˆ†æèƒŒæ™¯ï¼Œä¸è¦åç¦»åŸå§‹åˆ†æçš„æ ¸å¿ƒå†…å®¹
2. **æä¾›ä¸“ä¸šå»ºè®®**: ç»“åˆæŠ€æœ¯æŒ‡æ ‡å’Œå¸‚åœºæƒ…å†µï¼Œç»™å‡ºä¸“ä¸šçš„æŠ•èµ„å»ºè®®
3. **è§£é‡ŠæŠ€æœ¯æ¦‚å¿µ**: å¦‚æœç”¨æˆ·è¯¢é—®æŠ€æœ¯æŒ‡æ ‡æˆ–åˆ†ææ–¹æ³•ï¼Œè¯·è¯¦ç»†è§£é‡Š
4. **é£é™©è¯„ä¼°**: å§‹ç»ˆæé†’ç”¨æˆ·æŠ•èµ„é£é™©ï¼Œå¼ºè°ƒæŠ•èµ„éœ€è¦è°¨æ…
5. **ä¿æŒä¸€è‡´æ€§**: ç¡®ä¿ä½ çš„å›ç­”ä¸åŸå§‹åˆ†æç»“æœä¿æŒä¸€è‡´

## å›ç­”è¦æ±‚

- ä¿æŒä¸“ä¸šã€å®¢è§‚çš„è¯­æ°”
- æä¾›å…·ä½“çš„æ•°æ®æ”¯æŒï¼Œæƒ…å†µæ¶åŠ£çš„æƒ…å†µä¸‹ï¼Œä¹Ÿå¯ä»¥ç»™å‡ºçœ‹ç©ºçš„æŒ‡å¼•
- è€ƒè™‘å¸‚åœºç‰¹ç‚¹å’Œé£é™©å› ç´ 
- å¯ç»“åˆä¸€äº›ä»“ä½å‡è®¾æ¥ç»™å‡ºæŒ‡å¼•
- å¯ç»™é•¿æœŸæŠ•èµ„ã€çŸ­æœŸæ“ä½œç­‰ä¸åŒè§’åº¦çš„å»ºè®®
- å¦‚æœç”¨æˆ·çš„é—®é¢˜è¶…å‡ºåˆ†æèŒƒå›´ï¼Œè¯·è¯´æ˜å¹¶æä¾›ç›¸å…³å»ºè®®
- å§‹ç»ˆå¼ºè°ƒæŠ•èµ„æœ‰é£é™©ï¼Œå»ºè®®ç”¨æˆ·è°¨æ…å†³ç­–

è¯·åŸºäºä»¥ä¸ŠèƒŒæ™¯ä¿¡æ¯å›ç­”ç”¨æˆ·çš„é—®é¢˜ã€‚
"""
        
        return system_prompt 